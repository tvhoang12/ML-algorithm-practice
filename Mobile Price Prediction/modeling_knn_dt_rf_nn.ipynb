{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Modeling: KNN, Decision Tree, Random Forest, Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "load_prepare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 908 rows and 17 columns\n",
      "Using 16 features for modeling\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "FILE_PATH = \"/media/hoang/HDD_Code/Tài liệu học tập/Kỳ 1 năm 4/Khai phá dữ liệu/mobiles_dataset_2025_clustered_labeled.csv\"\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "print(f\"Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "\n",
    "# Target and feature selection\n",
    "TARGET = 'Launched Price (USA)'\n",
    "\n",
    "# If your file contains columns with encoded companies/processors like in prior notebook, include them.\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if TARGET not in numeric_cols:\n",
    "    raise KeyError(f\"Target column '{TARGET}' not found as numeric column in dataframe\")\n",
    "feature_cols = [c for c in numeric_cols if c != TARGET]\n",
    "\n",
    "# Minimal cleaning: drop rows with missing target, impute numeric features later in pipeline\n",
    "df = df.dropna(subset=[TARGET]).reset_index(drop=True)\n",
    "X = df[feature_cols]\n",
    "y = df[TARGET]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features for modeling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8e48ba28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RAM</th>\n",
       "      <th>Front Camera</th>\n",
       "      <th>Back Camera</th>\n",
       "      <th>Battery Capacity</th>\n",
       "      <th>Screen Size</th>\n",
       "      <th>Launched Price (USA)</th>\n",
       "      <th>ROM</th>\n",
       "      <th>Company_Apple</th>\n",
       "      <th>Company_Honor</th>\n",
       "      <th>Company_Oppo</th>\n",
       "      <th>Company_Other</th>\n",
       "      <th>Company_Samsung</th>\n",
       "      <th>Company_Vivo</th>\n",
       "      <th>Processor_vec1</th>\n",
       "      <th>Processor_vec2</th>\n",
       "      <th>Processor_vec3</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105389</td>\n",
       "      <td>-0.710295</td>\n",
       "      <td>-0.298391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.49</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105389</td>\n",
       "      <td>-0.710295</td>\n",
       "      <td>-0.298391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.99</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105389</td>\n",
       "      <td>-0.710295</td>\n",
       "      <td>-0.298391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105389</td>\n",
       "      <td>-0.710295</td>\n",
       "      <td>-0.298391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.49</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105389</td>\n",
       "      <td>-0.710295</td>\n",
       "      <td>-0.298391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RAM  Front Camera  Back Camera  Battery Capacity  Screen Size  \\\n",
       "0    6           1.2          4.8               3.6          6.1   \n",
       "1    6           1.2          4.8               3.6          6.1   \n",
       "2    6           1.2          4.8               3.6          6.1   \n",
       "3    6           1.2          4.8               4.2          6.7   \n",
       "4    6           1.2          4.8               4.2          6.7   \n",
       "\n",
       "   Launched Price (USA)  ROM  Company_Apple  Company_Honor  Company_Oppo  \\\n",
       "0                  7.99  2.0              1              0             0   \n",
       "1                  8.49  4.0              1              0             0   \n",
       "2                  8.99  8.0              1              0             0   \n",
       "3                  8.99  2.0              1              0             0   \n",
       "4                  9.49  4.0              1              0             0   \n",
       "\n",
       "   Company_Other  Company_Samsung  Company_Vivo  Processor_vec1  \\\n",
       "0              0                0             0       -0.105389   \n",
       "1              0                0             0       -0.105389   \n",
       "2              0                0             0       -0.105389   \n",
       "3              0                0             0       -0.105389   \n",
       "4              0                0             0       -0.105389   \n",
       "\n",
       "   Processor_vec2  Processor_vec3  Cluster  \n",
       "0       -0.710295       -0.298391        0  \n",
       "1       -0.710295       -0.298391        0  \n",
       "2       -0.710295       -0.298391        0  \n",
       "3       -0.710295       -0.298391        0  \n",
       "4       -0.710295       -0.298391        0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "split_scale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (726, 16) (182, 16)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "RANDOM_STATE = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Preprocessing pipeline: impute then scale (fit on train)\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_prep = numeric_pipeline.fit_transform(X_train)\n",
    "X_test_prep = numeric_pipeline.transform(X_test)\n",
    "\n",
    "print('Shapes:', X_train_prep.shape, X_test_prep.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "55071bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current X columns: ['RAM', 'Front Camera', 'Back Camera', 'Battery Capacity', 'Screen Size', 'ROM', 'Company_Apple', 'Company_Honor', 'Company_Oppo', 'Company_Other', 'Company_Samsung', 'Company_Vivo', 'Processor_vec1', 'Processor_vec2', 'Processor_vec3', 'Cluster']\n",
      "Number of features: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Current X columns:\", X.columns.tolist())\n",
    "print(\"Number of features:\", X_train_prep.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eval_helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(true, pred):\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "    r2 = r2_score(true, pred)\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "def print_eval(name, true, pred):\n",
    "    res = evaluate_regression(true, pred)\n",
    "    print(f\"{name}: MAE={res['MAE']:.3f}, RMSE={res['RMSE']:.3f}, R2={res['R2']:.3f}\")\n",
    "    return res\n",
    "\n",
    "def _is_fitted(est):\n",
    "    try:\n",
    "        check_is_fitted(est)\n",
    "        return True\n",
    "    except (NotFittedError, AttributeError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "models_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_knn already fitted\n",
      "best_dt already fitted\n",
      "rf already fitted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure estimator objects exist\n",
    "# train with knn\n",
    "if 'best_knn' in globals() and isinstance(best_knn, int):\n",
    "    best_knn = KNeighborsRegressor(n_neighbors=best_knn)\n",
    "elif 'best_knn' not in globals():\n",
    "    best_knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# train with decision tree\n",
    "if 'best_dt' not in globals():\n",
    "    best_dt = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "# train with random forest\n",
    "if 'rf' not in globals():\n",
    "    try:\n",
    "        # Load the best model from pickle file\n",
    "        with open('best_random_forest.pkl', 'rb') as f:\n",
    "            rf = pickle.load(f)\n",
    "        print(\"Loaded best Random Forest model from pickle file\")\n",
    "    except FileNotFoundError:\n",
    "        # Fall back to default parameters if pickle file not found\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=200,          \n",
    "            max_depth=None,            \n",
    "            min_samples_split=5,       \n",
    "            min_samples_leaf=2,        \n",
    "            max_features='sqrt',       \n",
    "            bootstrap=True,            \n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1,                 \n",
    "            max_samples=0.8,          \n",
    "            criterion='squared_error', \n",
    "            oob_score=True            \n",
    "        )\n",
    "        print(\"Created new Random Forest model with default parameters\")\n",
    "# Fit if needed (use train data already prepared)\n",
    "for name, est in [('best_knn', best_knn), ('best_dt', best_dt), ('rf', rf)]:\n",
    "    if not _is_fitted(est):\n",
    "        print(f\"{name} not fitted -> fitting now\")\n",
    "        est.fit(X_train, y_train)\n",
    "    else:\n",
    "        print(f\"{name} already fitted\")\n",
    "# Build pipelines that include the fitted numeric_pipeline (so preprocessing is saved together)\n",
    "from sklearn.pipeline import Pipeline as SKPipeline\n",
    "knn_pipe = SKPipeline([('preprocessor', numeric_pipeline), ('model', best_knn)])\n",
    "dt_pipe  = SKPipeline([('preprocessor', numeric_pipeline), ('model', best_dt)])\n",
    "rf_pipe  = SKPipeline([('preprocessor', numeric_pipeline), ('model', rf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug information:\n",
      "X_train shape: (726, 16)\n",
      "X_test shape: (182, 16)\n",
      "X_train_prep shape: (726, 16)\n",
      "X_test_prep shape: (182, 16)\n",
      "\n",
      "Feature columns: ['RAM', 'Front Camera', 'Back Camera', 'Battery Capacity', 'Screen Size', 'ROM', 'Company_Apple', 'Company_Honor', 'Company_Oppo', 'Company_Other', 'Company_Samsung', 'Company_Vivo', 'Processor_vec1', 'Processor_vec2', 'Processor_vec3', 'Cluster']\n",
      "KNN: MAE=2.879, RMSE=4.159, R2=-0.041\n",
      "DecisionTree: MAE=3.428, RMSE=4.646, R2=-0.299\n",
      "RandomForest: MAE=2.980, RMSE=3.729, R2=0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/hoang/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/hoang/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>2.879335</td>\n",
       "      <td>4.159002</td>\n",
       "      <td>-0.041228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>3.427698</td>\n",
       "      <td>4.646051</td>\n",
       "      <td>-0.299379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>2.979988</td>\n",
       "      <td>3.729003</td>\n",
       "      <td>0.162946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MAE      RMSE        R2\n",
       "KNN           2.879335  4.159002 -0.041228\n",
       "DecisionTree  3.427698  4.646051 -0.299379\n",
       "RandomForest  2.979988  3.729003  0.162946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let's check and debug the data shapes\n",
    "print(\"Debug information:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"X_train_prep shape: {X_train_prep.shape}\")\n",
    "print(f\"X_test_prep shape: {X_test_prep.shape}\")\n",
    "print(\"\\nFeature columns:\", X.columns.tolist())\n",
    "# Evaluate models\n",
    "results = {}\n",
    "\n",
    "# KNN evaluation\n",
    "try:\n",
    "    knn_pred = best_knn.predict(X_test_prep)\n",
    "    results['KNN'] = print_eval('KNN', y_test, knn_pred)\n",
    "except Exception as e:\n",
    "    print(f\"KNN prediction failed: {e}\")\n",
    "\n",
    "# Decision Tree evaluation    \n",
    "try:\n",
    "    dt_pred = best_dt.predict(X_test_prep)\n",
    "    results['DecisionTree'] = print_eval('DecisionTree', y_test, dt_pred)\n",
    "except Exception as e:\n",
    "    print(f\"Decision Tree prediction failed: {e}\")\n",
    "\n",
    "# Random Forest evaluation\n",
    "try:\n",
    "    rf_pred = rf.predict(X_test_prep)\n",
    "    results['RandomForest'] = print_eval('RandomForest', y_test, rf_pred)\n",
    "except Exception as e:\n",
    "    print(f\"Random Forest prediction failed: {e}\")\n",
    "\n",
    "# Display results\n",
    "summary = pd.DataFrame(results).T\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "save_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: knn_model.pkl, decision_tree_model.pkl, random_forest_model.pkl,\n",
      "       knn_model.joblib, decision_tree_model.joblib, random_forest_model.joblib,\n"
     ]
    }
   ],
   "source": [
    "# Save sklearn models with pkl\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Tạo pipeline chứa cả preprocessing đã fit + model (tiện cho inference)\n",
    "knn_pipe = Pipeline([('preprocessor', numeric_pipeline), ('model', best_knn)])\n",
    "dt_pipe  = Pipeline([('preprocessor', numeric_pipeline), ('model', best_dt)])\n",
    "rf_pipe  = Pipeline([('preprocessor', numeric_pipeline), ('model', rf)])\n",
    "\n",
    "# Lưu bằng pickle (.pkl) \n",
    "with open('knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_pipe, f)\n",
    "with open('decision_tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_pipe, f)\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_pipe, f)\n",
    "\n",
    "print('Saved: knn_model.pkl, decision_tree_model.pkl, random_forest_model.pkl,')\n",
    "print('       knn_model.joblib, decision_tree_model.joblib, random_forest_model.joblib,')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cefd5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded preprocessor components\n",
      "Model's expected features: ['RAM' 'Front Camera' 'Back Camera' 'Battery Capacity' 'Screen Size' 'ROM'\n",
      " 'Company_Apple' 'Company_Honor' 'Company_Oppo' 'Company_Other'\n",
      " 'Company_Samsung' 'Company_Vivo' 'Processor_vec1' 'Processor_vec2'\n",
      " 'Processor_vec3' 'Cluster']\n",
      "\n",
      "Processed features for iPhone 17:\n",
      "    RAM  Front Camera  Back Camera  Battery Capacity  Screen Size    ROM  \\\n",
      "0  16.0           2.4          4.8               5.0          6.0  512.0   \n",
      "\n",
      "   Company_Apple  Company_Honor  Company_Oppo  Company_Other  Company_Samsung  \\\n",
      "0              1              0             0              0                0   \n",
      "\n",
      "   Company_Vivo  Processor_vec1  Processor_vec2  Processor_vec3  Cluster  \n",
      "0             0       -0.079111       -0.547869       -0.258983        0  \n",
      "\n",
      "Checking for missing values:\n",
      "RAM                 0\n",
      "Front Camera        0\n",
      "Back Camera         0\n",
      "Battery Capacity    0\n",
      "Screen Size         0\n",
      "ROM                 0\n",
      "Company_Apple       0\n",
      "Company_Honor       0\n",
      "Company_Oppo        0\n",
      "Company_Other       0\n",
      "Company_Samsung     0\n",
      "Company_Vivo        0\n",
      "Processor_vec1      0\n",
      "Processor_vec2      0\n",
      "Processor_vec3      0\n",
      "Cluster             0\n",
      "dtype: int64\n",
      "\n",
      "Predicted Price for iPhone 17: $1003.57\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n",
    "class MobilePreprocessor:\n",
    "    def __init__(self):\n",
    "        # Define features in exact order from model\n",
    "        self.required_columns = [\n",
    "            'RAM', 'ROM', 'Front Camera', 'Back Camera',\n",
    "            'Battery Capacity', 'Screen Size',\n",
    "            'Processor_vec1', 'Processor_vec2', 'Processor_vec3',\n",
    "            'Company_Apple', 'Company_Honor', 'Company_Oppo',\n",
    "            'Company_Other', 'Company_Samsung', 'Company_Vivo', 'Cluster'\n",
    "        ]\n",
    "        self.vectorizer = None\n",
    "        self.pca = None\n",
    "        self.top_companies = ['Apple', 'Samsung', 'Oppo', 'Honor', 'Vivo']\n",
    "\n",
    "    def clean_numeric(self, value, remove_str=\"\", round_to_int=False):\n",
    "        try:\n",
    "            value = str(value).replace(remove_str, \"\").replace(\",\", \"\")\n",
    "            import re\n",
    "            match = re.search(r'\\d+', value)\n",
    "            return float(match.group()) if match else np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def preprocess_input(self, phone_data):\n",
    "        # Initialize output DataFrame with correct column order\n",
    "        processed = pd.DataFrame(0, index=[0], columns=self.required_columns)\n",
    "        \n",
    "        # Process numeric features\n",
    "        numeric_mappings = {\n",
    "            'RAM': ('GB', True, 1),\n",
    "            'ROM': ('GB', True, 1),\n",
    "            'Front Camera': ('MP', False, 0.1),\n",
    "            'Back Camera': ('MP', False, 0.1),\n",
    "            'Battery Capacity': ('mAh', False, 0.001),\n",
    "            'Screen Size': ('inches', False, 1)\n",
    "        }\n",
    "\n",
    "        for col, (unit, round_int, scale) in numeric_mappings.items():\n",
    "            if col in phone_data.columns:\n",
    "                val = self.clean_numeric(phone_data[col].iloc[0], unit, round_int)\n",
    "                processed[col] = val * scale if not pd.isna(val) else 0\n",
    "\n",
    "        # Company encoding\n",
    "        if \"Company Name\" in phone_data.columns:\n",
    "            company = phone_data[\"Company Name\"].iloc[0]\n",
    "            if company in self.top_companies:\n",
    "                processed[f\"Company_{company}\"] = 1\n",
    "            else:\n",
    "                processed[\"Company_Other\"] = 1\n",
    "\n",
    "        # Processor features\n",
    "        if all([self.vectorizer, self.pca, \"Processor\" in phone_data.columns]):\n",
    "            try:\n",
    "                text = phone_data[\"Processor\"].iloc[0]\n",
    "                tfidf = self.vectorizer.transform([str(text)])\n",
    "                pca_result = self.pca.transform(tfidf.toarray())\n",
    "                \n",
    "                for i in range(3):\n",
    "                    col = f\"Processor_vec{i+1}\"\n",
    "                    processed[col] = pca_result[0,i] if i < pca_result.shape[1] else 0\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Processor encoding failed - {e}\")\n",
    "\n",
    "        # Ensure exact column order\n",
    "        return processed[self.required_columns]\n",
    "\n",
    "    def load_preprocessor(self):\n",
    "        \"\"\"Load saved vectorizer and PCA\"\"\"\n",
    "        try:\n",
    "            with open('processor_vectorizer.pkl', 'rb') as f:\n",
    "                self.vectorizer = pickle.load(f)\n",
    "            with open('processor_pca.pkl', 'rb') as f:\n",
    "                self.pca = pickle.load(f)\n",
    "            print(\"✓ Loaded preprocessor components\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading preprocessor: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def predict_price(phone_data):\n",
    "    \"\"\"Predict phone price using preprocessed data and saved model\"\"\"\n",
    "    \n",
    "    # Initialize preprocessor\n",
    "    preprocessor = MobilePreprocessor()\n",
    "    if not preprocessor.load_preprocessor():\n",
    "        return None\n",
    "    \n",
    "    # Preprocess input data\n",
    "    processed_data = preprocessor.preprocess_input(phone_data)\n",
    "    \n",
    "    # Load and predict with model\n",
    "    try:\n",
    "        with open('best_random_forest.pkl', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        print(\"Model features:\", model.feature_names_in_)\n",
    "        prediction = model.predict(processed_data)\n",
    "        return float(prediction[0]) * 100  # Convert to USD\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Prediction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocessor = MobilePreprocessor()\n",
    "    if preprocessor.load_preprocessor():\n",
    "        # Example data for iPhone 17 (predicted specs)\n",
    "        iphone17_data = pd.DataFrame({\n",
    "            'RAM': ['16GB'],\n",
    "            'ROM': ['512GB'],\n",
    "            'Front Camera': ['24MP'],\n",
    "            'Back Camera': ['48MP'],\n",
    "            'Battery Capacity': ['5000mAh'],\n",
    "            'Screen Size': ['6.7 inches'],\n",
    "            'Company Name': ['Apple'],\n",
    "            'Processor': ['A16 Bionic'],\n",
    "            'Cluster': [2]  \n",
    "        })\n",
    "        \n",
    "        # Load model first to get correct feature order\n",
    "        try:\n",
    "            with open('best_random_forest.pkl', 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            print(\"Model's expected features:\", model.feature_names_in_)\n",
    "            \n",
    "            # Process and predict\n",
    "            processed_data = preprocessor.preprocess_input(iphone17_data)\n",
    "            \n",
    "            # Ensure feature order matches model's expectations\n",
    "            if hasattr(model, 'feature_names_in_'):\n",
    "                processed_data = processed_data[model.feature_names_in_]\n",
    "            \n",
    "            print(\"\\nProcessed features for iPhone 17:\")\n",
    "            print(processed_data)\n",
    "            print(\"\\nChecking for missing values:\")\n",
    "            print(processed_data.isna().sum())\n",
    "            \n",
    "            # Get price prediction\n",
    "            prediction = model.predict(processed_data)\n",
    "            print(f\"\\nPredicted Price for iPhone 17: ${float(prediction[0]) * 100:.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Inspect feature importance from RandomForest via rf.feature_importances_ if desired.\n",
    "- Further tuning (e.g., RandomizedSearchCV), target transformation (log), or categorical encoding may improve performance.\n",
    "- Adjust dataset path and feature selection according to your processed CSV structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
