{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VFa4dnaK-Xo"
      },
      "outputs": [],
      "source": [
        "#import lib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download data"
      ],
      "metadata": {
        "id": "YeVbt3ElLsyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive') #mount drive first then read data from Colab\n",
        "\n",
        "for dirname, _, filenames in os.walk('/drive/MyDrive/Colab Notebooks'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "df = pd.read_csv(\"/drive/MyDrive/Colab Notebooks/emails.csv\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "0i_00jysLvbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download packages\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "gOaIBvdiSDWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomSample = df[\"text\"].sample(3)\n",
        "for text in randomSample:\n",
        "  print(text,'\\n')"
      ],
      "metadata": {
        "id": "UcclGSz6SZOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocessing_text(text):\n",
        "  # Lowercase the text\n",
        "  text = text.lower()\n",
        "\n",
        "  # Tokenize the text\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  # Remove punctuation and non-alphanumeric characters\n",
        "  tokens = [word for word in tokens if word.isalnum()]\n",
        "\n",
        "  # Remove stopwords\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "  # Initialize steming\n",
        "  stemmer = PorterStemmer()\n",
        "  tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "  # Join tokens back into a processed text\n",
        "  processed_text = ' '.join(tokens)\n",
        "\n",
        "  return processed_text\n",
        "\n",
        "# Download punkt_tab\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Assign a new column with processed text\n",
        "df['processed_text'] = df['text'].apply(preprocessing_text)\n",
        "df['processed_text'].sample(5)"
      ],
      "metadata": {
        "id": "qr9DeOgzUsr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_text = df['processed_text']\n",
        "y = df['spam']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_text, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "3r4yK8BSWvIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_counts = [y_train.value_counts()[1], y_test.value_counts()[1]]\n",
        "non_spam_counts = [y_train.value_counts()[0], y_test.value_counts()[0]]\n",
        "\n",
        "x_labels = [\"Train\", \"Test\"]\n",
        "\n",
        "plt.bar(x_labels, spam_counts, label='Spam')\n",
        "plt.bar(x_labels, non_spam_counts, bottom=spam_counts, label='Not Spam')\n",
        "plt.title('Spam vs Not Spam in Train and Test Sets')\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UPFA5rlPXGFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize = CountVectorizer()#vectorize the data\n",
        "x_train_vectorized = vectorize.fit_transform(x_train)\n",
        "x_test_vectorized = vectorize.transform(x_test)\n",
        "\n",
        "print(f\"X_train_vec: {x_train_vectorized.toarray().shape}\")\n",
        "print(f\"X_test_vec: {x_test_vectorized.toarray().shape}\")"
      ],
      "metadata": {
        "id": "BKDLaLJZZItU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "LTF1Q5-dZqfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert data to pytorch tensor\n",
        "X_train_tensor = torch.tensor(x_train_vectorized.toarray(),\n",
        "                             dtype=torch.float32,\n",
        "                             device=device)\n",
        "y_train_tensor = torch.tensor(y_train.values,\n",
        "                             dtype=torch.float32,\n",
        "                             device=device)\n",
        "X_test_tensor = torch.tensor(x_test_vectorized.toarray(),\n",
        "                             dtype=torch.float32,\n",
        "                             device=device)\n",
        "y_test_tensor = torch.tensor(y_test.values,\n",
        "                             dtype=torch.float32,\n",
        "                             device=device)"
      ],
      "metadata": {
        "id": "9JaiQEIlZ7T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_set = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_set,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=False)"
      ],
      "metadata": {
        "id": "Tn9unYi2dkYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class MultinomialNB:\n",
        "    def __init__(self, alpha = 1):\n",
        "        \"\"\"\n",
        "        Hàm khởi tạo\n",
        "        alpha: Tham số làm mượt Laplace (smoothing)\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.priors_ = {}\n",
        "        self.likelihoods_ = {}\n",
        "        self.classes_ = set()\n",
        "        self.vocabulary_ = set()\n",
        "        self.n_vocab_ = 0\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        n_docs = len(X_train)\n",
        "\n",
        "        class_counts = {}\n",
        "        all_docs_by_class = {}\n",
        "\n",
        "        for doc, c in zip(X_train, y_train):\n",
        "            if c not in self.classes_:\n",
        "                self.classes_.add(c)\n",
        "                class_counts[c] = 0\n",
        "                all_docs_by_class[c] = []\n",
        "\n",
        "            class_counts[c] += 1\n",
        "\n",
        "            words = doc.split()\n",
        "            all_docs_by_class[c].extend(words)\n",
        "            for word in words:\n",
        "                self.vocabulary_.add(word)\n",
        "\n",
        "        self.n_vocab_ = len(self.vocabulary_)\n",
        "\n",
        "        for c in self.classes_:\n",
        "            self.priors_[c] = class_counts[c] / n_docs\n",
        "\n",
        "\n",
        "        total_words_by_class = {}\n",
        "        word_counts_by_class = {}\n",
        "\n",
        "        for c in self.classes_:\n",
        "            total_words_by_class[c] = len(all_docs_by_class[c]) # N_c\n",
        "\n",
        "            # Đếm số lần xuất hiện của từng từ trong class c\n",
        "            counts_for_this_class = {}\n",
        "            for word in all_docs_by_class[c]:\n",
        "                counts_for_this_class[word] = counts_for_this_class.get(word, 0) + 1\n",
        "            word_counts_by_class[c] = counts_for_this_class\n",
        "\n",
        "\n",
        "        for c in self.classes_:\n",
        "            self.likelihoods_[c] = {}\n",
        "            # Mẫu số chung cho class c\n",
        "            denom = total_words_by_class[c] + (self.alpha * self.n_vocab_)\n",
        "\n",
        "            # Tính P(word|c) cho MỌI TỪ trong từ điển\n",
        "            for word in self.vocabulary_:\n",
        "                # Lấy số lần từ 'word' xuất hiện trong class 'c'\n",
        "                count = word_counts_by_class[c].get(word, 0)\n",
        "\n",
        "                # Tử số\n",
        "                num = count + self.alpha\n",
        "\n",
        "                self.likelihoods_[c][word] = num / denom\n",
        "\n",
        "    def _predict_one(self, doc):\n",
        "        \"\"\"\n",
        "        Dự đoán class cho MỘT văn bản (đây là hàm nội bộ)\n",
        "        \"\"\"\n",
        "        scores = {}\n",
        "        words = doc.split()\n",
        "\n",
        "        for c in self.classes_:\n",
        "            # Bắt đầu bằng log của Xác suất Tiên nghiệm\n",
        "            score = np.log(self.priors_[c])\n",
        "\n",
        "            # Cộng dồn log của các Xác suất Có điều kiện\n",
        "            for word in words:\n",
        "                if word in self.vocabulary_:\n",
        "                    score += np.log(self.likelihoods_[c][word])\n",
        "\n",
        "            scores[c] = score\n",
        "\n",
        "        return max(scores, key=scores.get)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Dự đoán class cho một LIST các văn bản mới.\n",
        "        X_test: list các văn bản (vd: [\"free offer\", \"call me\"])\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for doc in X_test:\n",
        "            predictions.append(self._predict_one(doc))\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "49H__zsD1-F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#init model\n",
        "model_spam_filter = MultinomialNB(alpha=1)\n",
        "# Train the MultinomialNB model\n",
        "model_spam_filter.fit(x_train, y_train)\n",
        "print(\"Model training complete.\")\n"
      ],
      "metadata": {
        "id": "0MeQXMKUjfbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "spam_email = \"\"\"Here are this week's five freeCodeCamp resources that are worth your time:\n",
        "\n",
        "1. freeCodeCamp just published a new course taught by legendary Harvard computer science professor Dr. David J. Malan. This comprehensive cybersecurity for beginners course will teach you how to secure accounts, databases, and entire software systems. Dr. Malan also shares tons of practical tips for securing your privacy in an increasingly adversarial world. (8 hour YouTube course): https://www.freecodecamp.org/news/learn-cybersecurity-from-harvard-university\n",
        "\n",
        "2. freeCodeCamp also published a guide to passing the Certified Kubernetes Administrator Exam. Beau Carnes teaches this course, which will walk you through key DevOps concepts. You'll start by setting up your K8s practice environment. Then you'll bootstrap a multi-node cluster and your control plane. You'll learn about Helm, High Availability Autoscaling, CoreDNS, and more. (2 hour YouTube course): https://www.freecodecamp.org/news/prepare-for-the-kubernetes-administrator-certification-and-pass/\n",
        "\n",
        "3. On this week's freeCodeCamp podcast, I interview a software engineer who got his first developer job at age 45. Eric Carlson is a self-taught software engineer at Cisco. In his early 20s, he worked his way up to manager at the busiest Domino's Pizza in Canada. He eventually went to college and studied liberal arts, then worked as a teacher for two decades before teaching himself programming using freeCodeCamp. He was able to gradually pivot into a developer role within the big telecom company where he was working. (1 hour watch or listen in your favorite podcast app): https://www.freecodecamp.org/news/first-dev-job-at-45-interview-with-self-taught-freecodecamp-grad-eric-carlson-podcast-194/\n",
        "\n",
        "4. Learn how to build high-performance mobile apps using Google's open-source Flutter framework. freeCodeCamp uses Flutter for our Android and iPhone apps, and it's way easier than maintaining two separate app codebases. This Flutter handbook will teach you how to efficiently lay out your apps with minimum widget rebuilds. You'll learn state management techniques, asynchronous patterns, and image caching best practices. You'll also learn how to use Isolates and lazy loading to make your apps really snappy. (full length handbook): https://www.freecodecamp.org/news/how-to-build-scalable-and-performant-flutter-applications-a-handbook-for-devs/\n",
        "\n",
        "5. Learn Serverless Architecture using C# .NET and Azure cloud. This jam-packed course will teach you common microservice patterns, Onion Architecture, IoT functions, and more. (5 hour YouTube course): https://www.freecodecamp.org/news/serverless-and-microservices-with-c-and-azure/\n",
        "\n",
        "The freeCodeCamp community is working hard on so many improvements to our core curriculum. You should support our charity's mission, and by extension the entire open source ecosystem that relies on our learning resources: https://www.freecodecamp.org/donate\n",
        "\n",
        "Quote of the Week: “Most developer stories about learning to code involve having time to do things like go to meetups, build side projects, grind LeetCode, and so on. I didn’t have time or energy to do any of these things with a baby at home. So I found another way into my first developer job. For me, I had to find a way to get paid to code at my non-coding job. First I found a way to code for 5% of my job, then 10%, then a jump to 50%, and finally a jump to a 100% coding role.” — Software Engineer Eric Carlson on how he transitioned into a developer role within his current company at age 45, on this week's freeCodeCamp podcast\n",
        "\n",
        "Until next week, happy coding.\n",
        "\n",
        "-- Quincy Larson\n",
        "\n",
        "Teacher and founder of freeCodeCamp.org\n",
        "\n",
        "If these aren't worth your time, you can turn them off: https://www.freecodecamp.org/ue/7eTUUxGrt9IIdSkFAxxQj\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "non_spam_email = \"\"\"Subject: Meeting Agenda for Tomorrow\n",
        "\n",
        "Hi Team,\n",
        "\n",
        "I hope this email finds you well. I wanted to remind everyone about the meeting scheduled for tomorrow at 10:00 AM. Below is the agenda:\n",
        "\n",
        "1. Review of project milestones\n",
        "2. Discussion on upcoming deadlines\n",
        "3. Any other business\n",
        "\n",
        "Please come prepared with any updates or questions you may have. Looking forward to a productive meeting.\n",
        "\n",
        "Best regards,\n",
        "Mr. Bannerjee\n",
        "\"\"\"\n",
        "\n",
        "X_test = [spam_email, non_spam_email]\n",
        "X_check = [1, 0]\n",
        "\n",
        "# test\n",
        "# 3. DỰ ĐOÁN\n",
        "predictions = model_spam_filter.predict(X_test)\n",
        "\n",
        "# 4. XEM KẾT QUẢ\n",
        "print(f\"--- Kết quả dự đoán ---\")\n",
        "for doc, pred in zip(X_test, predictions):\n",
        "    if pred == 1:\n",
        "        print(f\"'{doc}'  ==>  Dự đoán: Spam\")\n",
        "    else:\n",
        "        print(f\"'{doc}'  ==>  Dự đoán: Not Spam\")\n",
        "accuracy = np.mean(np.array(predictions) == np.array(X_check))\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "kKRLjz_-o0Ot",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# đánh giá model\n",
        "def evaluate_classification_model(model, X_test, y_test_true):\n",
        "    print(f\"--- Đánh giá Model: {model.__class__.__name__} ---\")\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    pos_label = 1\n",
        "\n",
        "    accuracy = accuracy_score(y_test_true, y_pred)\n",
        "\n",
        "    precision = precision_score(y_test_true, y_pred, pos_label=pos_label, zero_division=0)\n",
        "    recall = recall_score(y_test_true, y_pred, pos_label=pos_label, zero_division=0)\n",
        "    f1 = f1_score(y_test_true, y_pred, pos_label=pos_label, zero_division=0)\n",
        "\n",
        "    print(f\"Nhãn thật (True):    {y_test_true}\")\n",
        "    print(f\"Nhãn dự đoán (Pred): {y_pred}\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Accuracy:   {accuracy * 100:.2f} %\")\n",
        "    print(f\"Precision (cho '{pos_label}'): {precision * 100:.2f} %\")\n",
        "    print(f\"Recall (cho '{pos_label}'):    {recall * 100:.2f} %\")\n",
        "    print(f\"F1-Score (cho '{pos_label}'):   {f1 * 100:.2f} %\")\n",
        "\n",
        "    labels = sorted(list(set(y_test_true)))\n",
        "    cm = confusion_matrix(y_test_true, y_pred, labels=labels)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "X_test = [\n",
        "    \"free offer\",         # Spam\n",
        "    \"call me\",            # Ham\n",
        "    \"send free stuff\",    # Spam\n",
        "    \"my office tomorrow\", # Ham\n",
        "    \"new offer call me\"   # Ham\n",
        "]\n",
        "y_test_true = [\n",
        "    1,\n",
        "    0,\n",
        "    1,\n",
        "    0,\n",
        "    0\n",
        "]\n",
        "\n",
        "# Đánh giá model\n",
        "evaluate_classification_model(model_spam_filter, X_test, y_test_true)"
      ],
      "metadata": {
        "id": "Pi-XoMW3Foqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}